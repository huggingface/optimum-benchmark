defaults:
  - backend: onnxruntime
  # order of inheritance, last one overrides previous ones
  - _base_ # inherits from base config
  - _inference_ # inherits from inference config
  - _lm_sweep_ # inherits from gpt sweep config
  - _self_ # for hydra 1.1 compatibility

experiment_name: tensorrt_inference_onnxruntime_lm_sweep
device: cuda

backend:
  use_cache: false
  provider: TensorrtExecutionProvider
