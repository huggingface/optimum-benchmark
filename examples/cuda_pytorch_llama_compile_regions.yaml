defaults:
  - benchmark
  - scenario: inference
  - launcher: process
  - backend: pytorch
  - _base_
  - _self_

name: cuda_pytorch_llama_compile_regions

launcher:
  device_isolation: true
  device_isolation_action: warn

backend:
  device: cuda
  device_ids: 0
  no_weights: true
  torch_compile: true
  torch_dtype: bfloat16
  task: feature-extraction
  torch_compile_target: regions
  model: NousResearch/Llama-2-13b-hf

scenario:
  input_shapes:
    batch_size: 4
    sequence_length: 256

  forward_kwargs:
    use_cache: false
