name: CLI CPU LlamaCpp Tests

on:
  workflow_dispatch:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
    types:
      - opened
      - reopened
      - synchronize
      - labeled
      - unlabeled

concurrency:
  cancel-in-progress: true
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}

jobs:
  run_cli_cpu_llama_cpp_tests:
    if: ${{
      (github.event_name == 'push') ||
      (github.event_name == 'workflow_dispatch') ||
      contains( github.event.pull_request.labels.*.name, 'cli') ||
      contains( github.event.pull_request.labels.*.name, 'cpu') ||
      contains( github.event.pull_request.labels.*.name, 'llama_cpp') ||
      contains( github.event.pull_request.labels.*.name, 'cli_cpu_llama_cpp')
      }}

    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install requirements
        run: |
          pip install uv
          uv pip install --upgrade pip
          uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
          uv pip install -e .[testing,llama-cpp]
        env:
          UV_SYSTEM_PYTHON: 1

      - name: Run tests
        run: pytest tests/test_cli.py -s -k "cli and cpu and llama_cpp"

      - name: Run examples
        run: pytest tests/test_examples.py -s -k "cli and cpu and llama_cpp"
